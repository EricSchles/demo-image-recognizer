{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognizer Demo with ScienceOps\n",
    "Deploying an image tagging model using neural networks + Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 model for Keras\n",
    "[Paper here](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)\n",
    "\n",
    "This is the [Keras](http://keras.io/) model of the 16-layer network used by the VGG team in the ILSVRC-2014 competition.\n",
    "\n",
    "It has been obtained by directly converting the [Caffe model](https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md) provived by the authors.\n",
    "\n",
    "Details about the network architecture can be found in the following arXiv paper:\n",
    "\n",
    "    Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "    K. Simonyan, A. Zisserman\n",
    "    arXiv:1409.1556\n",
    "    \n",
    "\n",
    "In the paper, the VGG-16 model is denoted as configuration `D`. It achieves 7.5% top-5 error on ILSVRC-2012-val, 7.4% top-5 error on ILSVRC-2012-test.\n",
    "\n",
    "Please cite the paper if you use the models.\n",
    "\n",
    "### Contents:\n",
    "\n",
    "model and usage demo: see `vgg-16_keras.py`\n",
    "\n",
    "weights: [vgg16_weights.h5](https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "Download the weights from this link: https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing and put them in a directory called `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "└── vgg16_weights.h5\r\n",
      "\r\n",
      "0 directories, 1 file\r\n"
     ]
    }
   ],
   "source": [
    "! tree data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [\" \".join(row.split(' ')[1:]) for row in open(\"./labels.txt\").read().strip().split('\\n')]\n",
    "im = cv2.resize(cv2.imread('images/pig.jpg'), (224, 224)).astype(np.float32)\n",
    "# im = cv2.resize(cv2.imread('images/pickup-truck.jpg'), (224, 224)).astype(np.float32)\n",
    "# im = cv2.resize(cv2.imread('images/cat.jpg'), (224, 224)).astype(np.float32)\n",
    "im[:,:,0] -= 103.939\n",
    "im[:,:,1] -= 116.779\n",
    "im[:,:,2] -= 123.68\n",
    "im = im.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test pretrained model\n",
    "model = VGG_16('data/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "It's a hog, pig, grunter, squealer, Sus scrofa\n",
      "{'guess': \"It's a hog, pig, grunter, squealer, Sus scrofa\"}\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(im)\n",
    "pred = dict(zip(labels, model.predict_proba(im)[0]))\n",
    "best_guess = labels[np.argmax(out)]\n",
    "print \"It's a %s\" % best_guess\n",
    "print { \"guess\": \"It's a %s\" % best_guess}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pig.jpg)\n",
    "\n",
    "<center><h3>`{\"guess\": \"hog, pig, grunter, squealer, Sus scrofa\"}`</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying to ScienceOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yhat import Yhat, YhatModel, preprocess\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import base64\n",
    "\n",
    "class ImageRecognizer(YhatModel):\n",
    "    REQUIREMENTS = [\n",
    "        \"opencv\"\n",
    "    ]\n",
    "    @preprocess(in_type=dict, out_type=dict)\n",
    "    def execute(self, data):\n",
    "        img64 = data['image64']\n",
    "        binaryimg = base64.decodestring(img64)\n",
    "        pilImage = Image.open(StringIO(binaryimg))\n",
    "        image = np.array(pilImage)\n",
    "        resized_image = cv2.resize(image, (224, 224)).astype(np.float32)\n",
    "        resized_image[:,:,0] -= 103.939\n",
    "        resized_image[:,:,1] -= 116.779\n",
    "        resized_image[:,:,2] -= 123.68\n",
    "        resized_image = resized_image.transpose((2,0,1))\n",
    "        resized_image = np.expand_dims(resized_image, axis=0)\n",
    "\n",
    "        out = model.predict(resized_image)\n",
    "        pred = dict(zip(labels, model.predict_proba(im)[0]))\n",
    "        best_guess = labels[np.argmax(out)]\n",
    "        print \"It's a %s\" % best_guess\n",
    "        return { \"guess\": best_guess }\n",
    "\n",
    "\n",
    "testdata = {\n",
    "    \"image64\": open('./test-image.base64', 'rb').read()\n",
    "}\n",
    "print ImageRecognizer().execute(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "It's a hog, pig, grunter, squealer, Sus scrofa\n",
      "{'guess': 'hog, pig, grunter, squealer, Sus scrofa'}\n",
      "extracting model\n",
      "model specified requirements\n",
      " [+] opencv (warning: unversioned)\n",
      "requirements automatically detected\n",
      " [+] yhat==1.5.0\n",
      " [+] Keras==1.0.4\n",
      "model variables\n",
      " [+] im <type 'numpy.ndarray'> 595.9KiB\n",
      " [+] model <class 'keras.models.Sequential'> 536.7MiB\n",
      " [+] labels <type 'list'> 26.6KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transfering Model: |############################|100% Time: 00:02:51   3.32 M/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Model successfully uploaded. Your model will begin building momentarily. Please see https://sandbox.yhathq.com/ for more details',\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yh = Yhat(USERNAME, APIKEY, URL)\n",
    "yh.deploy(\"ImageRecognizer\", ImageRecognizer, globals(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
